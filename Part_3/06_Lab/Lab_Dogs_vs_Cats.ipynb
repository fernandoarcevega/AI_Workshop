{"cells":[{"cell_type":"markdown","source":["<p align=\"left\">\n","  <a href=\"https://colab.research.google.com/github/fernandoarcevega/AI_Workshop/blob/main/Part_3/06_Lab/Lab_Dogs_vs_Cats.ipynb\" target=\"_parent\">\n","    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" width=\"200\">\n","  </a>\n","</p>"],"metadata":{"id":"DTYBWsVklMuA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"meTUB8bfP2Z8"},"outputs":[],"source":["###############################################\n","# Author 1: Wilfrido GÃ³mez-Flores (CINVESTAV) #\n","# Author 2: Fernando Arce-Vega (CIO)          #\n","# e-mail 1: wgomez@cinvestav.mx               #\n","# e-mail 2: farce@cio.mx                      #\n","# Date:     nov/11/2025                       #\n","# Subject:  Dogs vs. Cats with CNN            #\n","###############################################"]},{"cell_type":"markdown","metadata":{"id":"KlRhSuRXsDvV"},"source":["# Classifying `Dogs vs. Cats` Images Using a `CNN`\n","In this exercise, we will implement a `CNN` to classify images from the [`Dogs vs. Cats`](https://www.kaggle.com/c/dogs-vs-cats/data) database. We will also perform information augmentation and transfer learning.\n","\n","The `Dogs vs. Cats` database consists of `25,000` training images of dogs and cats. The goal is to train a classifier to distinguish between these two types of pets. For this example, we will use `2,000` images to train our model, `1,000` for validation, and `2,000` for testing."]},{"cell_type":"code","source":["# Change: Runtime to GPU"],"metadata":{"id":"teF01mxWWZKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check GPU details\n","!nvidia-smi"],"metadata":{"id":"jjH10NIiWbq2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UtxqCqGXw9Bx"},"outputs":[],"source":["# Libraries\n","import numpy as np                                                    # Numerical array operations\n","import matplotlib.pyplot as plt                                       # Data plotting/visualization\n","import tensorflow as tf                                               # Machine learning\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator   # Batch generator\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  # Model evaluation\n","import os                                                             # Interaction with the operating system"]},{"cell_type":"code","source":["# Install gdown\n","!pip install -q gdown"],"metadata":{"id":"0qQsw7DmIhm3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download dogs_vs_cats.zip dataset\n","!gdown --id 1zRFN_O3chFutGP7_4__z8rWuGJulc4BW --output dogs_vs_cats.zip"],"metadata":{"id":"wt5td_XrUn5t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Unzip dogs_vs_cats.zip file\n","!unzip '/content/dogs_vs_cats.zip' -d '/content/'"],"metadata":{"id":"KitebZUEUrQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove dogs_vs_cats.zip file\n","!rm '/content/dogs_vs_cats.zip'"],"metadata":{"id":"MC1nR9ziVGID"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"63J4WaEX2McJ"},"outputs":[],"source":["# Paths\n","dataset = 'dogs-vs-cats'\n","path = '/content/' + dataset + '/'\n","\n","train_dir = path + 'training/'\n","val_dir = path + 'validation/'\n","test_dir = path + 'testing/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eyt-cOZ3B1S"},"outputs":[],"source":["# Data visualization\n","ncols = 10\n","nrows = 10\n","\n","folders = os.listdir(train_dir)\n","pictures = []\n","clas = []\n","\n","# Concatenating images\n","for folder in folders:\n","  pictures += [train_dir + folder + '/' + name for name in os.listdir(train_dir + folder)]\n","  clas += [folder for name in os.listdir(train_dir + folder)]\n","\n","# Shuffle data\n","ind = np.random.permutation(len(clas))\n","pictures = np.array(pictures)[ind]\n","clas = np.array(clas)[ind]\n","\n","# Create figure\n","fig, axs = plt.subplots(figsize=(20, 20))\n","plt.axis('off')\n","\n","print('Training images\\n')\n","\n","for i in range(ncols * nrows):\n","\n","  axs = fig.add_subplot(nrows, ncols, i + 1)\n","  img = plt.imread(pictures[i])\n","  axs.imshow(img, cmap='gray')\n","  axs.axis('off')\n","\n","  label = str(clas[i][:-1])\n","  plt.title(label)\n","\n","plt.show()"]},{"cell_type":"code","source":["# Batch generation\n","data_augmentation = True\n","\n","# Data augmentation\n","if data_augmentation:\n","  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0,\n","                                                                zoom_range=0.2,\n","                                                                rotation_range=0.2,\n","                                                                shear_range=0.2,\n","                                                                horizontal_flip=True)\n","# Without data augmentation\n","else:\n","  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n","\n","val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.0)\n","test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.0)\n","\n","batch_size = 32\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size = (224, 224),\n","    batch_size = batch_size,\n","    color_mode = 'rgb',\n","    class_mode = 'binary')\n","\n","val_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size = (224, 224),\n","    batch_size = batch_size,\n","    color_mode = 'rgb',\n","    class_mode = 'binary')\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size = (224, 224),\n","    batch_size = batch_size,\n","    color_mode = 'rgb',\n","    class_mode = 'binary')"],"metadata":{"id":"sYQMupTUX3cP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPB-4PzNk9Bi"},"outputs":[],"source":["# Visualization of the data augmentation\n","def plottingImages(images):\n","    plt.subplots(figsize = (20, 20))\n","    cols = 5\n","    rows = len(images) // cols\n","    plt.axis('off')\n","\n","    for c, img in enumerate(images):\n","        plt.subplot(rows, cols, c + 1)\n","        plt.imshow(img, cmap = 'gray')\n","        plt.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","augmented_images = [train_generator[0][0][0] for i in range(20)]\n","plottingImages(augmented_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcQd8bZ36-IV"},"outputs":[],"source":["# TO_DO: Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2vkMQWV_qFc"},"outputs":[],"source":["# TO_DO: Model description\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57CVFdCJ_s_6"},"outputs":[],"source":["# TO_DO: Compile model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j04udoNHbiu2"},"outputs":[],"source":["# Callbacks\n","model_path = '/content/' + 'model.keras'\n","\n","# Callbacks\n","early_stop = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_accuracy',\n","    patience=6,\n","    restore_best_weights=True)\n","\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n","    monitor='val_accuracy',\n","    factor=0.1,\n","    patience=3,\n","    min_lr=1e-6,\n","    verbose=1)\n","\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    filepath = model_path,\n","    save_best_only = True,\n","    monitor = 'val_accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SEpLX5meACcI"},"outputs":[],"source":["# TO_DO: Train model\n","epochs = 20\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ro-iZgKpAXcN"},"outputs":[],"source":["# Training and validation graphs\n","training_acc = history.history['accuracy']\n","validation_acc = history.history['val_accuracy']\n","\n","training_loss = history.history['loss']\n","validation_loss = history.history['val_loss']\n","\n","epocas = np.arange(len(training_loss))\n","\n","plt.figure(figsize=(10, 4))\n","plt.plot(epocas, training_acc, color='blue', label='Training Acc')\n","plt.plot(epocas, validation_acc, color = 'green', label='Validation Acc')\n","plt.title('ACC')\n","plt.xlabel('Epochs')\n","plt.ylabel('Acc')\n","plt.legend()\n","plt.show()\n","print()\n","\n","plt.figure(figsize = (10, 4))\n","plt.plot(epocas, training_loss, color='blue', label='Training MSR')\n","plt.plot(epocas, validation_loss, color = 'green', label='Validation MSR')\n","plt.title('MSE')\n","plt.xlabel('Epochs')\n","plt.ylabel('Error')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","source":["# Model prediction\n","batch = next(test_generator)\n","images = batch[0]\n","targets = batch[1]\n","\n","results = model.predict(images, verbose = 0)\n","results = np.round(results).reshape(len(results))\n","\n","# Indexing classes\n","dict_classes = test_generator.class_indices\n","dict_classes = {v:k for k, v in dict_classes.items()}\n","print(dict_classes)"],"metadata":{"id":"sq64Y5SsbhbN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data visualization\n","ncols = 5\n","nrows = 6\n","\n","# Create figure\n","fig, axs = plt.subplots(figsize=(20, 20))\n","plt.axis('off')\n","\n","print('Testing images\\n')\n","\n","for i in range(ncols * nrows):\n","\n","  axs = fig.add_subplot(nrows, ncols, i + 1)\n","  axs.imshow(images[i], cmap='gray')\n","  axs.axis('off')\n","\n","  label = str(dict_classes[results[i]])\n","  label = label[:-1]\n","\n","  if targets[i] != results[i]:\n","    plt.title(label, color='red')\n","\n","  else:\n","    plt.title(label)\n","\n","plt.show()"],"metadata":{"id":"Byj52jlxbh_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdc61xpcioF4"},"outputs":[],"source":["# Load model\n","filepath = model_path\n","model = tf.keras.models.load_model(filepath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jy4nWdKe08k6"},"outputs":[],"source":["# Model performance\n","loss_training, acc_training = model.evaluate(train_generator, verbose=1)\n","loss_validation, acc_validation = model.evaluate(val_generator, verbose=1)\n","loss_testing, acc_testing = model.evaluate(test_generator, verbose=1)"]},{"cell_type":"code","source":["# Print performance\n","print('Training loss:  ', loss_training)\n","print('Training acc:   ', acc_training)\n","print()\n","print('Validation loss:', loss_validation)\n","print('Validation acc: ', acc_validation)\n","print()\n","print('Test loss:      ', loss_testing)\n","print('Test acc:       ', acc_testing)"],"metadata":{"id":"Rr77pb9je05P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion matrix\n","cm = confusion_matrix(targets, results)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot()\n","plt.show()"],"metadata":{"id":"jGuwljDUfG4l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3JbPWrx2jQZF"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuClass":"premium","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}